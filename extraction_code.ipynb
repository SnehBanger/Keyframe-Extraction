{
  "nbformat": 3,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extraction_code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4yE2MSiyExm"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqM7RsrfyTj5"
      },
      "source": [
        "cap = cv2.VideoCapture('/content/Video.mp4')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hrTq8sZyYA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ddcb90e-fa6f-4af6-90e3-efcc25cae861"
      },
      "source": [
        "arr = np.empty((0, 1944), int)   #initializing 1944 dimensional array to store 'flattened' color histograms\n",
        "D=dict()   #to store the original frame (array)\n",
        "count=0    #counting the number of frames\n",
        "start_time = time.time()\n",
        "while cap.isOpened():\n",
        "    \n",
        "    # Read the video file.\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    # If we got frames.\n",
        "    if ret == True:\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  #since cv reads frame in bgr order so rearraning to get frames in rgb order\n",
        "        D[count] = frame_rgb   #storing each frame (array) to D , so that we can identify key frames later \n",
        "        \n",
        "        #dividing a frame into 3*3 i.e 9 blocks\n",
        "        height, width, channels = frame_rgb.shape\n",
        "\n",
        "        if height % 3 == 0:\n",
        "            h_chunk = int(height/3)\n",
        "        else:\n",
        "            h_chunk = int(height/3) + 1\n",
        "\n",
        "        if width % 3 == 0:\n",
        "            w_chunk = int(width/3)\n",
        "        else:\n",
        "            w_chunk = int(width/3) + 1\n",
        "\n",
        "        h=0\n",
        "        w= 0 \n",
        "        feature_vector = []\n",
        "        for a in range(1,4):\n",
        "            h_window = h_chunk*a\n",
        "            for b in range(1,4):\n",
        "                frame = frame_rgb[h : h_window, w : w_chunk*b , :]\n",
        "                hist = cv2.calcHist(frame, [0, 1, 2], None, [6, 6, 6], [0, 256, 0, 256, 0, 256])#finding histograms for each block  \n",
        "                hist1= hist.flatten()  #flatten the hist to one-dimensinal vector \n",
        "                feature_vector += list(hist1)\n",
        "                w = w_chunk*b\n",
        "                \n",
        "            h = h_chunk*a\n",
        "            w= 0\n",
        "\n",
        "                \n",
        "        arr =np.vstack((arr, feature_vector )) #appending each one-dimensinal vector to generate N*M matrix (where N is number of frames\n",
        "          #and M is 1944) \n",
        "        count+=1\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "final_arr = arr.transpose() #transposing so that i will have all frames in columns i.e M*N dimensional matrix \n",
        "#where M is 1944 and N is number of frames\n",
        "print(final_arr.shape)\n",
        "print(count)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- 20.56631565093994 seconds ---\n",
            "(1944, 1832)\n",
            "1832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GS3L60SybGg"
      },
      "source": [
        "from scipy.sparse import csc_matrix\n",
        "from scipy.sparse.linalg import svds, eigs\n",
        "A = csc_matrix(final_arr, dtype=float)\n",
        "\n",
        "#top 63 singular values from 76082 to 508\n",
        "u, s, vt = svds(A, k = 63)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YynXzuPhyc4t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6bd99a1-558d-4cd2-bc02-8fd2739ddc8d"
      },
      "source": [
        "print(u.shape, s.shape, vt.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1944, 63) (63,) (63, 1832)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Six5B-WcyqDD",
        "outputId": "2540308e-384a-45c3-cb8d-a758b233e824"
      },
      "source": [
        "print(list(s))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[507.58633979103627, 513.3394019469041, 542.5885461980106, 557.4615730264481, 581.1252578281169, 595.6523491133431, 625.86762511288, 667.3543038445862, 703.9369306867553, 785.003322644083, 824.1240297172756, 830.2095332996869, 862.3243911201391, 962.1678005881336, 993.188433535317, 1074.4879221595818, 1104.036330689477, 1174.3795871198802, 1310.4024628743764, 1429.8059729265522, 1436.0497628725564, 1784.0835463882906, 1920.5743747040267, 2075.5124822673374, 2235.9930038951475, 2450.8504358624946, 2789.861284247543, 3266.437872035349, 3467.454332697817, 3703.2744228804354, 4026.5120288278335, 4160.600410916419, 4339.992564704212, 4608.34076843354, 4872.711772927276, 5124.862670258988, 5276.3095425231095, 5668.146768603113, 5931.50792208964, 5952.291087578096, 6235.342567902845, 6697.2983210833945, 6776.9477144817065, 7065.201258998803, 7853.121480587884, 8067.823543248021, 8691.54870860473, 9140.661744359926, 9938.174572146696, 10316.757223295497, 10792.03020156712, 11187.86326121343, 11687.075188310097, 13425.115571459457, 13830.826759645011, 14644.218274242552, 15148.499757824606, 16712.593590009536, 17776.73443088512, 22769.41272124729, 30817.59754211365, 45793.98450615914, 76082.29505434034]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtttPx1Zyrc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40dc81a9-80d0-4ad3-c834-478d7df9ff3d"
      },
      "source": [
        "\n",
        "v1_t = vt.transpose()\n",
        "\n",
        "projections = v1_t @ np.diag(s) #the column vectors i.e the frame histogram data has been projected onto the orthonormal basis \n",
        "#formed by vectors of the left singular matrix u .The coordinates of the frames in this space are given by v1_t @ np.diag(s)\n",
        "#So we can see that , now we need only 63 dimensions to represent each column/frame \n",
        "print(projections.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1832, 63)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "008BTu0Hytba"
      },
      "source": [
        "#dynamic clustering of projected frame histograms to find which all frames are similar i.e make shots\n",
        "f=projections\n",
        "C = dict() #to store frames in respective cluster\n",
        "for i in range(f.shape[0]):\n",
        "    C[i] = np.empty((0,63), int)\n",
        "    \n",
        "#adding first two projected frames in first cluster i.e Initializaton    \n",
        "C[0] = np.vstack((C[0], f[0]))   \n",
        "C[0] = np.vstack((C[0], f[1]))\n",
        "\n",
        "E = dict() #to store centroids of each cluster\n",
        "for i in range(projections.shape[0]):\n",
        "    E[i] = np.empty((0,63), int)\n",
        "    \n",
        "E[0] = np.mean(C[0], axis=0) #finding centroid of C[0] cluster\n",
        "\n",
        "count = 0\n",
        "for i in range(2,f.shape[0]):\n",
        "    similarity = np.dot(f[i], E[count])/( (np.dot(f[i],f[i]) **.5) * (np.dot(E[count], E[count]) ** .5)) #cosine similarity\n",
        "    #this metric is used to quantify how similar is one vector to other. The maximum value is 1 which indicates they are same\n",
        "    #and if the value is 0 which indicates they are orthogonal nothing is common between them.\n",
        "    #Here we want to find similarity between each projected frame and last cluster formed chronologically. \n",
        "     \n",
        "    \n",
        "    if similarity < 0.9: #if the projected frame and last cluster formed  are not similar upto 0.9 cosine value then \n",
        "                         #we assign this data point to newly created cluster and find centroid \n",
        "                         #We checked other thresholds also like 0.85, 0.875, 0.95, 0.98\n",
        "                        #but 0.9 looks okay because as we go below then we get many key-frames for similar event and \n",
        "                        #as we go above we have lesser number of key-frames thus missed some events. So, 0.9 seems optimal.\n",
        "                        \n",
        "        count+=1         \n",
        "        C[count] = np.vstack((C[count], f[i])) \n",
        "        E[count] = np.mean(C[count], axis=0)   \n",
        "    else:  #if they are similar then assign this data point to last cluster formed and update the centroid of the cluster\n",
        "        C[count] = np.vstack((C[count], f[i])) \n",
        "        E[count] = np.mean(C[count], axis=0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNzSr0B-yvFe"
      },
      "source": [
        "b = []  #find the number of data points in each cluster formed.\n",
        "\n",
        "#We can assume that sparse clusters indicates \n",
        "#transition between shots so we will ignore these frames which lies in such clusters and wherever the clusters are densely populated indicates they form shots\n",
        "#and we can take the last element of these shots to summarise that particular shot\n",
        "\n",
        "for i in range(f.shape[0]):\n",
        "    b.append(C[i].shape[0])\n",
        "\n",
        "last = b.index(0)  #where we find 0 in b indicates that all required clusters have been formed , so we can delete these from C\n",
        "b1=b[:last ] #The size of each cluster."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13Uyz4M8zA1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7cf1ca0-9c91-46c4-9b02-e0247b9ad9aa"
      },
      "source": [
        "res = [idx for idx, val in enumerate(b1) if val >= 25] #so i am assuming any dense cluster with atleast 25 frames is eligible to \n",
        "#make shot.\n",
        "print(len(res)) #so total 25 shots with 46 (71-25) cuts"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq_YCVmrzCdR"
      },
      "source": [
        "GG = C #copying the elements of C to GG, the purpose of  the below code is to label each cluster so later \n",
        "#it would be easier to identify frames in each cluster\n",
        "for i in range(last):\n",
        "    p1= np.repeat(i, b1[i]).reshape(b1[i],1)\n",
        "    GG[i] = np.hstack((GG[i],p1))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBgrmT8JzEK6"
      },
      "source": [
        "#the purpose of the below code is to append each cluster to get multidimensional array of dimension N*64, N is number of frames\n",
        "F=  np.empty((0,64), int) \n",
        "for i in range(last):\n",
        "    F = np.vstack((F,GG[i]))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVaw5oiozFdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4df24cc-64ee-49ab-f19a-ebc2c51cbb81"
      },
      "source": [
        "#converting F (multidimensional array)  to dataframe\n",
        "\n",
        "colnames = []\n",
        "for i in range(1, 65):\n",
        "    col_name = \"v\" + str(i)\n",
        "    colnames+= [col_name]\n",
        "print(colnames)\n",
        "\n",
        "df = pd.DataFrame(F, columns= colnames)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19', 'v20', 'v21', 'v22', 'v23', 'v24', 'v25', 'v26', 'v27', 'v28', 'v29', 'v30', 'v31', 'v32', 'v33', 'v34', 'v35', 'v36', 'v37', 'v38', 'v39', 'v40', 'v41', 'v42', 'v43', 'v44', 'v45', 'v46', 'v47', 'v48', 'v49', 'v50', 'v51', 'v52', 'v53', 'v54', 'v55', 'v56', 'v57', 'v58', 'v59', 'v60', 'v61', 'v62', 'v63', 'v64']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0jIPOh3zQEG"
      },
      "source": [
        "\n",
        "df['v64']= df['v64'].astype(int)  #converting the cluster level from float type to integer type"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRGEqmBRzRoa"
      },
      "source": [
        "df1 =  df[df.v64.isin(res)]   #filter only those frames which are eligible to be a part of shot or filter those frames who are\n",
        "#part of required clusters that have more than 25 frames in it"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPXCjnsbzUpz"
      },
      "source": [
        "new = df1.groupby('v64').tail(1)['v64'] #For each cluster /group take its last element which summarize the shot i.e key-frame"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84bBmiRkzWMY"
      },
      "source": [
        "\n",
        "new1 = new.index #finding key-frames (frame number so that we can go back get the original picture)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRGeA0-Fqpf5"
      },
      "source": [
        "path = '/content/extracted_keyframes'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaMkl9hPzXcf"
      },
      "source": [
        "#output the frames in png format\n",
        "for c in new1:\n",
        "    frame_rgb1 = cv2.cvtColor(D[c], cv2.COLOR_RGB2BGR) #since cv consider image in BGR order\n",
        "    frame_num_chr = str(c)\n",
        "    file_name = 'frame'+ frame_num_chr +'.png'\n",
        "    cv2.imwrite((os.path.join(path, file_name)), frame_rgb1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H8V_C2MqguR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
